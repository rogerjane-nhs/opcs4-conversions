#!/usr/bin/env python3

""" Performs all the conversion tasks for OPCS-4 files.

    Converts CodesAndTitles_YYYYMMDD_2.txt to codes_YYYYMMDD.xml
    Converts MetaData_YYYYMMDD_2.txt to meta_YYYYMMDD.xml
    Converts TOCE_YYYYMMDD_2.xls (or TOCE_YYYYMMDD_2.csv if openpyxl not installed) to toce_YYYYMMDD.xml
    Converts Tabular_YYYYMMDD_2.rtf to BlockStructure_YYYYMMDD.csv (and .xlsx if openpyxl is installed)
    Converts Tabular_YYYYMMDD_2.rtf to ClaML_YYYYMMDD.xml
"""

## 27-08-2025 RJ 0.0.0 Create 'Block Structure' file
## 04-09-2025 RJ 0.0.1 Tidied up and added CSV and Excel output
## 05-09-2025 RJ 0.0.2 Excluded deleted and retired codes and generated notes sheet
## 03-12-2025 RJ 0.0.3 Stolen from make_block_structure to instead generate a CLAML file
## 10-12-2025 RJ 0.0.4 Tidied up to make more claML-like
## 11-12-2025 RJ 0.1.0 Merged in opcs2xml and consilidated everything to a single script

import argparse
import csv
import re
import sys

import xml.etree.ElementTree as ET

from collections import defaultdict
from pathlib import Path
from typing import TypeVar, NoReturn, Optional
from xml.dom import minidom

try:
    import openpyxl
    from openpyxl import Workbook
    from openpyxl.styles import Border, Side, PatternFill, Font, Alignment
except ImportError:
    openpyxl = None
    class Workbook:     # Needs to exist or the 'def output' fails
        pass

_force: bool = False    # Set to True (-f, --force) to force overwrite

T = TypeVar("T")
_func_cache = {}

def Fatal(msg: str) -> NoReturn:
    print(msg, file=sys.stderr)
    exit(99)

def FatalAt(file, line, text) -> NoReturn:
    Fatal(f"Fatal error in {file}:{line} - {text}")


def Debug(*args, **kwargs) -> None:
    # print(f"DEBUG: {msg}", file=sys.stderr)

    line = sys._getframe().f_back.f_lineno

    print(f"DBG {line}: ", *args, **kwargs, file=sys.stderr)

# Just experimenting if this is any use
def static_attr(name: str, default: T) -> T:
    frame = sys._getframe(1)
    code = frame.f_code

    # Cache the function object per code object
    func = _func_cache.get(code)
    if func is None:
        func = frame.f_locals.get(code.co_name) or frame.f_globals.get(code.co_name)
        if not callable(func):
            raise RuntimeError(f"Cannot resolve calling function: {code.co_name}")
        _func_cache[code] = func

    if not hasattr(func, name):
        setattr(func, name, default)
    return getattr(func, name)

def date_from_filename(filename: str) -> str | None:
    m = re.search(r"(\d{8})", filename)
    if m:
        return m.group(1)
    return None

def latest_file_with_date(directory: Path, pattern: str, name: str) -> Path:
    """ Get the (latest) file in the directory matching the pattern.  'name' is used in the error message.
    """
    date_re = re.compile(r"(\d{8})")   # matches YYYYMMDD
    filter = re.compile(pattern)

    candidates = []

    for f in [f for f in directory.iterdir() if f.is_file() and filter.match(f.name)]:
        dt = date_from_filename(f.name)
        if dt:
            candidates.append((dt, f))

    if not candidates:
        Fatal(f"I can't find any {name} files in {directory}")
        return None, None

    # Pick the file with the maximum date
    _, latest_file = max(candidates, key=lambda x: x[0] + x[1].name)
    return latest_file

def resolve_files(src: Path, dest: Path, pattern: str, template: str, name: str):
    """ Given src and dest from command line, along with a pattern for the filename, resolve the actual filenames

        Returns the src and dest paths
    """
    if src.is_dir():
        src = latest_file_with_date(src, pattern, name)
        if not dest.exists():
            dest.mkdir(parents=True, exist_ok=True)

    if dest.is_dir():
        dt = date_from_filename(src.name)
        if not dt:
            Fatal(f"Cannot determine date from {src.name}")
        dest = dest / template.replace("YYYYMMDD", dt)

    dest.parent.mkdir(parents=True, exist_ok=True)

    if dest.exists() and not _force:
        Fatal(f"Output file {dest} already exists - use --force to overwrite")

    return src, dest


def rtf_to_text(rtf_content: str) -> list[str]:
    """ Fillet RTF content, returning a list of plain text lines.

        We remove most of the RTF formatting, keeping the line structure and tabs.
    """
    # Remove groups like font/color tables: {\*\fonttbl...}, {\*\colortbl...}, etc.
    text = re.sub(r'{\\\*?\\[^{}]+}|{\\\*?[^{}]+}', '', rtf_content)

    # Convert escaped hex codes: \'hh â†’ corresponding character
    text = re.sub(r"\\'([0-9a-fA-F]{2})", lambda m: bytes.fromhex(m.group(1)).decode('latin1'), text)

    # Translate the RTF control words that we want to keep
    text = text.replace("\\pard", "\n").replace("\\par", "\n")
    text = text.replace("\\tab", "\t")

    # Remove remaining RTF control words (e.g. \b, \par, \fs24, etc.)
    text = re.sub(r'\\[-a-zA-Z]+\d* ?', '', text)

    # Remove escaped braces and backslashes
    text = text.replace('\\{', '{').replace('\\}', '}').replace('\\\\', '\\')

    # Remove leftover braces entirely
    text = re.sub(r'[{}]', '', text)

    # Normalize line breaks: RTF uses \par for paragraphs
    text = text.replace('\r', '\n').replace('\n\n', '\n')

    # Split into individual lines and strip whitespace
    lines = [line.strip() for line in text.splitlines() if line.strip()]

    return lines

# ClaML section here

def rubric(code: str, kind: str, text: str):
    """ Return a Rubric element
    """
    rubric = ET.Element("Rubric", id=code, kind=kind)
    label = ET.Element("Label")
    label.set("{http://www.w3.org/XML/1998/namespace}lang", "en")
    label.text = text
    rubric.append(label)
    return rubric

class Node:
    _instances: dict[str, "Node"] = {}

    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        cls._instances = {}      # separate dict for each subclass

    def __init__(self, code: int, title: str):
        self.__class__._instances[code] = self
        self.code = code.replace(" ", "")
        self.title = title
        self.parent = None
        self.children: list[Node] = []
        self._notes = []

    @classmethod
    def all(cls):
        """ Return a list of all the instances of this class
        """
        return list(cls._instances.values())

    @classmethod
    def __class_getitem__(cls, code: str):
        """ Get a specific instance of this class
        """
        return cls._instances[code]

    def add_child(self, child: "Node"):
        if child.code == self.code:
            print(f"Can't add self as child ({self.code})")
        self.children.append(child)
        child.parent = self

    def add_note(self, kind: str, note: str):
        """ Add a note including the 'kind' used when rendering it in a Rubric
        """
        self._notes.append((kind, note))

    def render_rubrics(self, claml: ET.Element):
        """ Render excludes, includes etc.
        """
        counters: dict[str, int] = defaultdict(int)
        for (kind, note) in self._notes:
            counters[kind] += 1
            i = counters[kind]
            claml.append(rubric(f"{self.code}{kind}_{i}", kind, note))

    def render_to(self, claml: ET.Element):
        elem = ET.Element("Class", code=self.code, kind=self.kind)
        if self.parent:
            elem.append(ET.Element("SuperClass", code=self.parent.code))

        for code in self.children:
            elem.append(ET.Element("SubClass", code=code.code))

        elem.append(rubric(self.code, "preferred", self.title))
        self.render_rubrics(elem)

        claml.append(elem)

        for codelong in self.children:
            codelong.render_to(claml)

class CodeLong(Node):
    """ Represent a long code - e.g. A01.1
    """
    def __init__(self, code: str, title: str):
        super().__init__(code, title)
        self.kind = "category"

class CodeShort(Node):
    """ Represent a short code - e.g. A01
    """

    def __init__(self, code: str, title: str):
        super().__init__(code, title)
        self.kind = "category"

class Block(Node):
    """ Represent a block of codes - e.g. A01-A11 Tissue of Brain
    """
    def __init__(self, code: str, title: str):
        # if "," in code:                         # Change F34, F65-F89 to F34-F89
        #     code = code[:3] + "-" + code[-3:]
        if "-" not in code:                         # Block codes mustn't match short codes so hyphenate to be sure
            code = f"{code}-{code}"
        super().__init__(code, title)
        self.kind = "block"

    def code_list(self):
        """ Render the codes as a nice list (A01-A03, A05-A06, A08, A10-A12)
        """
        groups: list[int] = []      # Each group is a list of (start, end)
        for code in self.children:
            num: str = code.code[1:]     # E.g. "A01" -> "01", "A12" -> "12"

            # If we're starting or this is not 1 beyoned the previous group, add a new group
            if not groups or int(groups[-1][1]) + 1 != int(num):
                groups.append([num, num])
                continue

            # Otherwise, update the last group
            groups[-1][1] = num

        chapter = self.parent.code      # E.g. "A"

        return ", ".join([f"{chapter}{start}" if start == end else f"{chapter}{start}-{chapter}{end}" for start, end in groups])

class Chapter(Node):
    """ Represent a chapter - e.g. A NERVOUS SYSTEM
    """
    def __init__(self, code: str, title: str):
        super().__init__(code, title)
        self.codes = []
        self.kind = "chapter"

    def add_codes(self, codes: list[str]):
        """ Add a list of codes such as A01, A02, A03, A05, A06, A08, A10, A11, A12
            We need to format them into a nice list (A01-A03, A05-A06, A08, A10-A12)
        """
        groups: list[int] = []      # Each group is a list of (start, end)
        for code in codes:
            chapter = code[0]
            num = code[1:]

            if not groups or int(groups[-1][1]) + 1 != int(num):
                groups.append([num, num])
                continue

            groups[-1][1] = num

        result = ", ".join([f"{chapter}{start}" if start == end else f"{chapter}{start}-{chapter}{end}" for start, end in groups])

        self.codes.append(result)

def make_claml(lines: list[str], name: str="OPCS-4.11", version: str="2025-12-10"):
    """ Create the claml file
    """
    claml = ET.Element("ClaML")

    claml.append(ET.Element("Meta", name="TopLevelSort", value="A B C D E F G H J K L M N P Q R S T U V W X Y Z"))
    claml.append(ET.Element("Meta", name="lang", value="en"))
    claml.append(ET.Element("Meta", name="css", value="opcs.css"))
    claml.append(ET.Element("Identifier", authority="NHS Digital", uid=name))
    claml.append(ET.Element("CodingSchemeId", authority="HL7", uid="1.2.826.0.1275.122"))
    claml.append(ET.Element("Title", name=name, version=version, date=version))

    def add_kinds(kind:str, kinds: dict[str, str], attr_name: Optional[str]=None):
        elem = ET.Element(f"{kind}Kinds")
        for name, attr in kinds.items():
            kwargs = {"name": name}
            if attr_name:
                kwargs[attr_name] = attr
            elem.append(ET.Element(f"{kind}Kind", **kwargs))
        claml.append(elem)

    class_kinds = {
        "chapter": None,
        "category": None,
        "block": None,
    }
    rubric_kinds = {
        "preferred": "false",
        "exclusion": "false",
        "preferred": "false",
        "inclusion": "false",
        "note": "false",
    }
    add_kinds("Class", class_kinds)
    add_kinds("Rubric", rubric_kinds, "inherited")

    part: int = 0               # Track if we're in part 1 or part 2
    chapter: Chapter = None     # Essentially pre-declaration - it'll be an actual Chapter before it's used
    block: Block = None         # Same
    thing: Node = None          # Used for tracking the last 'thing' we saw in part 2 so excludes and notes can be added to it
    note_kind: str = None       # Used for tracking the last 'note kind' we saw in part 2 so excludes and notes can be added to it
    skip_notes: int = 0         # Used to skip un-attributed notes after chapter headings

    for line in lines:
        # Keep track of which part we're in
        if m := re.match(r"Part (\d)", line):
            part = int(m.group(1))
            skip_notes = 1
            continue

        # We need to process part 1 to get the ranges
        if part == 1:                   # PART 1
            if "\t" in line:
                code, name = line.split("\t", 1)
                codeshort = CodeShort(code, name.strip())
                block.add_child(codeshort)
            else:
                # Chapter titles are X. NAME
                if m := re.match(r"(.)\. (.*)", line):         # E.g. A. NERVOUS SYSTEM
                    code = m.group(1)
                    title = m.group(2)
                    chapter = Chapter(code, title)
                    continue

                # Block titles are Title (range)
                if m := re.match(r"(.*?)\s*\((.*)\)\s*$", line):   # E.g. Tissue of brain (A01-A11)
                    title = m.group(1)
                    range = m.group(2)
                    block = Block(range, title)
                    chapter.add_child(block)

        else:                                                     # PART 2
            if m := re.match(r"([A-Z][0-9][0-9])\s+(.*)", line):    # E.g. A01 Major excision of tissue of brain
                code = m.group(1)
                codeshort = CodeShort[code]                         # Instantiated in PART 1
                thing = codeshort
                note_kind = None                                    # Stop untagged text being assigned
            elif m := re.match(r"([A-Z][0-9][0-9]\.[0-9])\s+(.*)", line):   # E.g. A01.1 Hemispherectomy
                code, name = m.groups()
                codelong = CodeLong(code, name.strip())
                codeshort.add_child(codelong)
                thing = codelong
                note_kind = None                                    # Stop untagged text being assigned
            elif m := re.match(r"CHAPTER (.*)", line):
                chapter = Chapter[m.group(1)]
                thing = chapter
                skip_notes = 2                                      # Following two lines would be seen as notes, but they're title/code spec
            else:                                                   # Probably Excludes:, Includes: or Note: or just text
                if m := re.match(r"(\w+):\s*(.*)", line):
                    match m.group(1):
                        case "Excludes":
                            note_kind = "exclusion"
                        case "Includes":
                            note_kind = "inclusion"
                        case "Note":
                            note_kind = "note"
                        case _:
                            print(f"Unrecognised kind: {m.group(1)}")
                            continue
                    line = m.group(2)
                elif m := re.match(r"Note at .* applies", line):   # There are notes that just say "Note at D02 applies" for example
                    note_kind = "note"
                elif m := re.match(r"SEE ALSO.*", line):            # There are notes that just say "SEE ALSO X98" for example
                    note_kind = "note"
                else:
                    if skip_notes:                                  # Skip unattributed notes after chapter headings
                        skip_notes -= 1
                        continue
                if note_kind:
                    skip_notes = 0
                    thing.add_note(note_kind, line)
                else:
                    pass
                    # This occurs on three lines:
                    #   "ANAESTHETICS" - appears on a line on its own just before Y80
                    #   "NON-OPERATIONS" - This and the following line appear just before Y90
                    #   Within OPCS-4 more specific terms are available within the main chapters therefore the codes below should not be used
                    # They are currently ignored but might add something in the future
                    # print(f"dunno what to do with: {line}")

    for chapter in Chapter.all():
        chapter.render_to(claml)

    return claml

def xml_esc(text):
    """ Perform XML escaping of anything that doesn't sit nicely as element text

        These are attributes enclosed in " so just need the four escapes to be safe.
    """

    return (text
        .replace("&", "&amp;")
        .replace("\"", "&quot;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
    )

def out(fd, level, text):
    """ Output the text to the file as a line indented level 'indents'
    """

    indent = level * "    "
    nl = "\n"
    fd.write(indent + text + nl)

def do_codes(src: Path, dest: Path):
    """ Process CodesAndTitles txt -> xml

        Source is nicely TAB separated - two columns.
    """

    src, dest = resolve_files(src, dest, r"CodesAndTitles.*\.txt", "codes_YYYYMMDD.xml", "codes")
    # Column 1 is the CODE
    # Column 2 is the TITLE
    with dest.open("w") as d:
        out(d, 0, "<?xml version=\"1.0\" encoding=\"UTF-8\"?>")
        out(d, 0, "<dsv xmlns=\"https://www.digital.nhs.uk/opcs/codes\">")
        with src.open() as fd:
            lineno = 0
            for line in fd:
                lineno += 1
                line = line.rstrip()
                if not line:
                    continue
                try:
                    code, title = line.split("\t", 1)
                    code = xml_esc(code)
                    title = xml_esc(title)
                    output = f"<code CODE=\"{xml_esc(code)}\" TITLE=\"{title}\"/>"
                    out(d, 1, output)
                except Exception as e:
                    FatalAt(src, lineno, f"{e}")
        out(d, 0, "</dsv>")
    print(f"Processed {lineno:,} lines into {dest}")

def do_meta(src: Path, dest: Path):
    """ Process MetaData txt -> xml

        src is space separated with data at columns
    """
    # 1           A011        MAJOR EXCISION OF TISSUE OF BRAIN                           HEMISPHERECTOMY                                                                                              01                                 1
    # 012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
    # 0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23
    src, dest = resolve_files(src, dest, r"MetaData.*\.txt", "meta_YYYYMMDD.xml", "meta data")
    with dest.open("w") as d:
        out(d, 0, "<?xml version=\"1.0\" encoding=\"UTF-8\"?>")
        out(d, 0, "<dsv xmlns=\"https://www.digital.nhs.uk/opcs/meta\">")
        with src.open("rb") as fd:
            try:
                for lineno, line in enumerate(fd, start=1):
                    if b'\xa0' in line:
                        highlight = line.replace(b'\xa0', b'*').decode().rstrip()
                        line = line.replace(b'\xa0', b' ')
                        print(f"0xa0 replaced on line {lineno}: {highlight}")
                    line = line.decode()
                    line = line.rstrip()
                    if not line:
                        continue
                    line += " " * (228 - len(line))
                    attrs = {}
                    a = line[0:12].rstrip()                         # We don't use the leading 1
                    oc = line[12:24].rstrip()                       # operation code provided without '.'
                    operation_code = oc[:3] + "." + oc[3:]          # Add in the '.'
                    operation_name_3 = line[24:84].rstrip()
                    operation_name_4 = line[84:191].rstrip()
                    sex_scrutiny = line[191:193].rstrip()           # Not always provided - appears just before the '01' in the example
                    status_operation = line[193:218].rstrip()
                    delivery = len(line[218:].rstrip())             # Appears as a '1' in a column depending on the delivery method
                    if delivery:
                        attrs["METHOD_DELIVERY"] = delivery - 1
                    attrs["OPERATION_CODE"] = operation_code
                    attrs["OPERATION_NAME_3"] = operation_name_3
                    attrs["OPERATION_NAME_4"] = operation_name_4
                    if sex_scrutiny:
                        attrs["SEX_SCRUTINY"] = sex_scrutiny
                    attrs["STATUS_OPERATION"] = status_operation

                    output = "<meta"

                    for name, value in attrs.items():
                        entry = f"{name}=\"{xml_esc(str(value))}\""
                        if len(output + entry) > 80:
                            out(d, 1, output)
                            output = "    "
                        output += " " + entry
                    out(d, 1, output + "/>")
            except Exception as e:
                FatalAt(src, lineno, f"{e}")
        out(d, 0, "</dsv>")
    print(f"Processed {lineno:,} lines into {dest}")

def do_toce(src, dest):
    """ Process TOCE xls -> xml

        src is a CSV saved from Excel
    """
    src, dest = resolve_files(src, dest, r"TOCE.*\.(csv|xlsx)", "toce_YYYYMMDD.xml", "TOCE")

    if src.suffix.lower() == ".xlsx":
        if not openpyxl:
            Fatal(f"TOCE source file must be .csv if openpyxl is not installed - open in Excel and save as .csv")
        wb = openpyxl.load_workbook(src)
        ws = wb.active
        for row in ws:
            Debug(row)
            break
        Fatal("Sorry - can't actually do .xlsx TOCE files yet")

    # Fields are:
    # 1..n-1    Codes for OPCS4.2 ... OPCS 4.10...
    # n         Description
    # n+1       Notes for OPCS {version} ... OPCS 4.2 - we're only interested in the 4.{version} one in column n+1 (older notes are to the right of it)
    # n is 10 for version 4.10, 11 for version 4.11 etc.

    biggest_major = biggest_minor = 0
    with open(dest, "w") as d:
        out(d, 0, "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>")
        out(d, 0, "<dsv xmlns=\"https://www.digital.nhs.uk/opcs/toce\">")
        with open(src, newline='') as fd:
            lineno = 0
            spamreader = csv.reader(fd)
            for row in spamreader:
                lineno += 1
                if lineno == 1:
                    for cell in row:
                        if m := re.match(r"OPCS (\d+)\.(\d+)", cell):
                            major, minor = map(int, m.groups())
                            if minor > biggest_minor:
                                biggest_minor = minor
                                biggest_major = major
                    if not biggest_minor:
                        FatalAt(src, lineno, "Can't find version number (OPCS x.x) in first row of {src}")
                    n = biggest_minor
                    descr_col = n - 1
                    notes_col = n
                    continue

                attrs = {}
                descr = row[descr_col]
                parts = descr.split(": ")           # Appears as "code: description"
                if len(parts) != 2:
                    FatalAt(src, lineno, f"Expecting 'code: description', for '{descr}'")
                attrs["DESCRIPTION"] = parts[1]
                for i in range(n - 1):
                    attrs[f"OPCS_4{i + 2}"] = row[i]
                if row[notes_col]:
                    attrs["NOTES"] = row[notes_col]

                output = "<code"
                for name, value in attrs.items():
                    entry = f"{name}=\"{xml_esc(str(value))}\""
                    if len(output + entry) > 80:
                        out(d, 1, output)
                        output = "    "
                    output += " " + entry
                out(d, 1, output + "/>")
        out(d, 0, "</dsv>")
    print(f"Processed {lineno:,} lines into {dest}")

def do_block(src, dest):

    # If we're not specifying a specific file on the command line, we'll do both csv and xlsx if we can
    dest_is_dir = not dest.is_file()
    src, dest = resolve_files(src, dest, r"Tabular.*\.rtf", "BlockStructure_YYYYMMDD.csv", "Block Structure")

    with src.open("r", encoding="utf-8") as f:
        rtf_content = f.read()

    lines = rtf_to_text(rtf_content)
    # Keep track of the parts for the 'path' column
    part = 0
    volume = 1
    part = 2
    chapter = 0
    subsection = 1
    category = 1
    category_entry = 1

    want_chapter = False
    chap = "?"
    range = "?"
    cat ="?"
    subcat = "?"

    codes = []
    ranges = {}

    prev_part = 1
    prev_chap = ""
    prev_cat = ""
    prev_subcat = ""

    writing_csv = writing_xlsx = False

    if dest_is_dir or dest.suffix == ".csv":
        csv_file = dest.with_suffix(".csv")
        csv_f = csv_file.open("w", newline="", encoding="utf-8")
        writer = csv.writer(csv_f)
        writing_csv = True
        print(f"CSV file will be created as:   {csv_file}")

    if dest_is_dir or dest.suffix == ".xlsx":
        sheet_file = dest.with_suffix(".xlsx")
        if openpyxl:

            wb = Workbook()
            ws_notes = wb.active
            ws_notes.title = "Notes"

            ws = wb.create_sheet("OPCS4 Block Structure")
            writing_xlsx = True
            print(f"Excel file will be created as: {sheet_file}")
            # Define some styles here as, although the calls are cached internally, they're still relatively slow
            header_fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")
            header_font = Font(name="Arial", bold=True)
            centre_align = Alignment(horizontal="center")

            body_font = Font(name="Arial")

            thin_border = Border(left=Side(style="thin"), right=Side(style="thin"), top=Side(style="thin"), bottom=Side(style="thin"))
        else:
            print(f"A .xlsx will NOT be produced in {sheet_file.name} as the 'openpyxl' module is not installed.  Use 'pip3 install openpyxl' to get it.")

    def process_codes(codes: list[str], title: str):
        """ Process a list of codes such as A01, A02, A03, A05, A06, A08, A10, A11, A12
            and format them into a nice list (A01-A03, A05-A06, A08, A10-A12) preceding the title
            Then map all the codes to the result
        """
        groups: list[int] = []      # Each group is a list of (start, end)
        for code in codes:
            chapter = code[0]
            num = code[1:]

            if not groups or int(groups[-1][1]) + 1 != int(num):
                groups.append([num, num])
                continue

            groups[-1][1] = num
        result = ", ".join([f"{chapter}{start}" if start == end else f"{chapter}{start}-{chapter}{end}" for start, end in groups]) + f" {title}"

        for code in codes:
            ranges[code] = result

    def part1(line: str):
        """ Collect the information on range that can only be gleaned from part 1
        """
        part1.title = static_attr("title", "?")
        if not "\t" in line:
            if codes:
                process_codes(codes, part1.title)
            codes.clear()
            part1.title = re.sub(r"\s*\([^)]*\)$", "", line)
            return
        code = line.split("\t", 1)[0]
        codes.append(code)

    def output(row: list[str], style: str, sheet: Optional[Workbook]=None):
        """ Output a row in whatever format(s) we need

            style and sheet only apply if we're outputing to Excel
            style:  "plain", "heading" or "body"
            sheet:  The sheet to output to (default is ws)
        """

        if writing_xlsx:        # Excel
            output.row_counts = static_attr("row_counts", {})
            if openpyxl:
                if not sheet:
                    sheet = ws

                # This is much quicker than using ws.row_count on deep sheets
                last_row = output.row_counts.get(sheet, 0) + 1
                output.row_counts[sheet] = last_row

                sheet.append(row)
                row = sheet[last_row]
                if style == "heading":
                    for cell in row:       # Heading row wants some styling
                        cell.fill = header_fill
                        cell.font = header_font
                        cell.alignment = centre_align
                        cell.border = thin_border
                elif style == "body":
                    for cell in row:           # All cells want borders
                        cell.border = thin_border

                for cell in row:                # All rows want just font setting
                    cell.font = body_font

        if writing_csv:
            writer.writerow(row)

    def note(chap: str, range: str, cat: str, subcat: Optional[str]=None):
        """ Note the deletion of a code if we're generating an Excel file
        """
        if not writing_xlsx:
            return
        note.count = static_attr("count", 0)
        if note.count == 0:
            output(["The following are not included:"], "plain", sheet=ws_notes)
            output([], "plain", sheet=ws_notes)
            output(["Chapter", "Range", "Category", "Subcategory"], "heading", sheet=ws_notes)

            # ws_notes.append(["Chapter", "Range", "Category", "Subcategory"])
        note.count += 1
        output([chap, range, cat, subcat], "body", sheet=ws_notes)
        # ws_notes.append([chap, range, cat, subcat])

    output(["Path", "Chapter", "Range", "Category", "Subcategory"], "heading")
    total = len(lines)
    last_pc = -1
    for lineno, line in enumerate(lines):

        # Keep track of progress as Excel generation is slothful
        if writing_xlsx:
            pc = int(lineno / total * 100)
            if pc != last_pc:
                print(f"\r{pc}% complete...", end="", flush=True, file=sys.stderr)

        # Keep track of which part we're in
        if m := re.match(r"Part (\d)", line):
            part = int(m.group(1))
            continue

        # We need to process part 1 to get the ranges
        if part == 1:
            part1(line)
            continue

        # We need to push an extra line to part1 so it processes the last range
        if part == 2 and prev_part == 1:
            part1("")
        prev_part = part

        # Chapters are a line saying "CHAPTER A", followed by the chapter name on the next line
        if line.startswith("CHAPTER "):
            chap = line[8:]             # Bit nasty, but effective
            want_chapter = True
            continue

        if want_chapter:                # The chapter name line
            chap = chap + ". " + line
            want_chapter = False
            continue

        # We're now only interested in lines of the form code<TAB>text
        if "\t" not in line:
            continue

        code, text = line.split("\t", 1)
        text = text.strip()
        m = re.match(r"([A-Z][0-9]+)(\.[0-9])?", code)

        # Skip lines that don't start with a code
        if not m:
            continue

        code = m.group(1)       # A01
        sub = m.group(2)        # .1

        # there wasn't a .n part then it's a category so just note it
        if not sub:
            cat = f"{code} {text}"
            if text.lower().startswith("code deleted"):
                note(chap, range, cat)
                continue
            continue

        subcat = f"{code}{sub} {text}"
        range = ranges[code]
        if text.lower().startswith("code retired"):
            note(chap, range, cat, subcat)
            continue

        if text.lower().startswith("code deleted"):
            note(chap, range, cat, subcat)
            continue

        # Bump our numbers up for the 'path' column
        if chap != prev_chap:
            chapter += 1
            category = 1
            category_entry = 1
        elif cat != prev_cat:
            category += 1
            category_entry = 1
        else:
            category_entry += 1
        prev_chap = chap
        prev_cat = cat
        path = f"/Volume[{volume}]/Part[{part}]/Chapter[{chapter}]Subsection[{subsection}]/Category[{category}]/CategoryEntry[{category_entry}]"

        output([path, chap, range, cat, subcat], "body")

    if writing_csv:
        csv_f.close()

    if writing_xlsx:
        for col, width in {"A": 42, "B": 26, "C": 40, "D": 128}.items():
            ws_notes.column_dimensions[col].width = width + 17
            ws_notes.auto_filter.ref = f"A3:D{ws_notes.max_row}"
            ws_notes.freeze_panes = ws_notes.cell(4, 1)

        for col, width in {"A": 50, "B": 42, "C": 26, "D": 40, "E": 128}.items():
            ws.column_dimensions[col].width = width + 17
            ws.auto_filter.ref = f"A1:E{ws.max_row}"
            ws.freeze_panes = ws.cell(2, 1)

        wb.save(sheet_file)
        wb.close()

        print("\r.              \r", end="", file=sys.stderr)

def do_claml(src, dest):
    src, dest = resolve_files(src, dest, r"Tabular.*\.rtf", "claml_YYYYMMDD.xml", "ClaML")

    with src.open("r", encoding="utf-8") as f:
        rtf_content = f.read()

    lines = rtf_to_text(rtf_content)
    claml = make_claml(lines, name="OPCS-4.11", version="2025-12-10")

    # We want it pretty so need to reparse it...
    rough_string = ET.tostring(claml, 'utf-8')
    reparsed = minidom.parseString(rough_string)
    pretty_xml = reparsed.toprettyxml(indent="    ")

    with dest.open("w") as f:
        f.write(pretty_xml)

if __name__ == "__main__":

    # Read myself to get version etc. from the comments above
    with open(__file__) as source_fd:
        VERSION = "?"
        for source_line in source_fd:
            if source_line.startswith("##"):
                _, DATE, INITS, VERSION, COMMENT = source_line.split(" ", 4)
                COMMENT = COMMENT.strip()
            else:
                if VERSION != "?":
                    break

    epilog = """
    Convert provided OPCS-4 files to other formats.

    Either specify a source directory containing the files to convert or specify individual files.
    The results will be written to the same directory as the source or to a destination directory or file if specified.

    If no conversion is specified all files in the source directory will be converted.

    The usual M.O. is therefore to put all source files in a directory then just give that directory and a destionation,
    which will be created if it doesn't exist.

    If the openpyxl module is installed then the 'block' conversion will also generate an Excel file.
    """

    class MyParser(argparse.ArgumentParser):
        def error(self, message):
            # Print full help
            self.print_help(sys.stderr)
            # Then print the error message
            self.exit(2, f"\nError: {message}\n")

    parser = MyParser(
        description=f"OPCS-4 conversion utility - version {VERSION} ({DATE})",
        epilog=epilog,
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument("src", help="Source directory or file")
    parser.add_argument("dest", help="Destination directory - default as src", nargs="?")
    parser.add_argument("-f", "--force", action="store_true", help="Force overwrite of existing files")
    parser.add_argument("-c", "--codes", action="store_true", help="Convert CodesAndTitles*.txt to codes_YYYYMMDD.xml")
    parser.add_argument("-m", "--meta", action="store_true", help="Convert MetaData*.txt to meta_YYYYMMDD.xml")
    parser.add_argument("-t", "--toce", action="store_true", help="Convert TOCE*.xlsx (or TOCE*.csv) to toce_YYYYMMDD.txt")
    parser.add_argument("-b", "--block", action="store_true", help="Convert Tabular*.rtf to BlockStructure_YYYYMMDD.csv (and .xlsx)")
    parser.add_argument("-l", "--claml", action="store_true", help="Convert Tabular*.rtf to claml_YYYYMMDD.xml")

    args = parser.parse_args()

    _force = args.force

    # Get the number of conversion types requested
    type_count = sum(bool(arg) for arg in (args.codes, args.meta, args.toce, args.block, args.claml))
    if type_count == 0:
        args.codes = args.meta = args.toce = args.block = args.claml = True

    src = Path(args.src or ".")
    dest = Path(args.dest or src)
    if not src.is_file() and not src.is_dir():
        Fatal("Source must be a file or directory")

    if type_count > 1 and dest.is_file():
        Fatal(f"I can't convert multiple types to a single file: {dest}")

    if type_count > 1 and src.is_file():
        Fatal(f"I can't convert multiple types from a single file: {src}")

    if args.codes:
        do_codes(src, dest)

    if args.meta:
        do_meta(src, dest)

    if args.toce:
        do_toce(src, dest)

    if args.block:
        do_block(src, dest)

    if args.claml:
        do_claml(src, dest)

    exit(0)
